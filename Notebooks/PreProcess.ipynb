{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import random \n",
    "from random import randint\n",
    "import numpy as Numpy\n",
    "from numpy import asarray\n",
    "from matplotlib import pyplot as plt\n",
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read folders\n",
    "base_dir = \"../Material-Recognition-Data/image/\"\n",
    "augmented_dir = \"../Material-Recognition-Data/augmented_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmenting Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(img, h, w):\n",
    "    img = cv2.resize(img, (w, h), cv2.INTER_CUBIC)\n",
    "    return img \n",
    "\n",
    "def zoom(img):\n",
    "    val = random.uniform(0.5, 1)\n",
    "    h, w = img.shape[:2]\n",
    "    h_taken = int(val*h)\n",
    "    w_taken = int(val*w)\n",
    "    h_start = randint(0, h-h_taken)\n",
    "    w_start = randint(0, w-w_taken)\n",
    "    augmented_img = img[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n",
    "    augmented_img = fill(augmented_img, h, w)\n",
    "    return augmented_img\n",
    "\n",
    "def vertical_shift(img):\n",
    "    ratio = random.uniform(-0.7, 0.7)\n",
    "    h, w = img.shape[:2]\n",
    "    to_shift = h*ratio\n",
    "    if ratio > 0: \n",
    "        augmented_img = img[:int(h-to_shift), :, :]\n",
    "    else:\n",
    "        augmented_img = img[int(-1*to_shift):, :, :]\n",
    "    augmented_img = fill(augmented_img, h, w)\n",
    "    return augmented_img\n",
    "\n",
    "def horizontal_shift(img):\n",
    "    ratio = random.uniform(-0.7, 0.7)\n",
    "    h, w = img.shape[:2]\n",
    "    to_shift = w*ratio\n",
    "    if ratio > 0:\n",
    "        augmented_img = img[:, :int(w-to_shift), :]\n",
    "    else:\n",
    "        augmented_img = img[:, int(-1*to_shift):, :]\n",
    "    augmented_img = fill(augmented_img, h, w)\n",
    "    return augmented_img\n",
    "\n",
    "\n",
    "def augment_images(images_list, class_name, total_augment):\n",
    "    class_dir = augmented_dir + class_name + \"/\"\n",
    "    images_per_class = total_augment \n",
    "\n",
    "    if not os.path.isdir(class_dir):\n",
    "        os.makedirs(class_dir)\n",
    "\n",
    "    original_count = len(images_list)\n",
    "    no_required_images = images_per_class - original_count\n",
    "    print(\"Augmenting \" + str(no_required_images) + \" images for this category ...\")\n",
    "\n",
    "    # augment images\n",
    "    while no_required_images > 0: \n",
    "        copy_img = images_list[no_required_images % original_count]\n",
    "        ran_choice = randint(1, 5)\n",
    "\n",
    "        # apply diff transformations based on random selection\n",
    "        if ran_choice == 1:\n",
    "            # rotate counter clockwise\n",
    "            augmented_img = cv2.flip(copy_img, 0)\n",
    "        elif ran_choice == 2:\n",
    "            # rotate clockwise\n",
    "            augmented_img = cv2.flip(copy_img, 1)\n",
    "        elif ran_choice == 3:\n",
    "            # random zoom on image\n",
    "           augmented_img = zoom(copy_img)\n",
    "        elif ran_choice == 4:\n",
    "            # vertical shift image\n",
    "            augmented_img = vertical_shift(copy_img)\n",
    "        elif ran_choice == 5:\n",
    "            # horizontal shift image\n",
    "            augmented_img = horizontal_shift(copy_img)\n",
    "\n",
    "        # resize image \n",
    "        resized_img = cv2.resize(augmented_img, (0, 0), fx=0.5, fy=0.5)\n",
    "        # append to existing list\n",
    "        images_list.append(resized_img)\n",
    "        # minus required images\n",
    "        no_required_images -= 1\n",
    "\n",
    "    # save all images to new dir \n",
    "    for idx in range(len(images_list)):\n",
    "        curr_img = images_list[idx]\n",
    "\n",
    "        # convert BGR format to RGB format\n",
    "        curr_img = cv2.cvtColor(curr_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # convert array back to img and save\n",
    "        curr_img = Image.fromarray(curr_img)\n",
    "        # pad index with 0s \n",
    "        img_idx = f'{idx+1:04}'\n",
    "        img_name = class_name + \"_\" + img_idx + \".png\"\n",
    "        curr_img.save(class_dir + img_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read images and augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current class that is being processed: fabric\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: foliage\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: glass\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: leather\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: metal\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: paper\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: plastic\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: stone\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: water\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: wood\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "image_folders = glob.glob(base_dir + \"*\")\n",
    "image_folders = sorted(image_folders)\n",
    "\n",
    "for folder in range(len(image_folders)):\n",
    "    # get class name\n",
    "    class_name = os.path.basename(image_folders[folder])\n",
    "    # get all paths of images in class\n",
    "    class_path_list = glob.glob(base_dir + class_name + \"/*\")\n",
    "\n",
    "    # get list of images in class \n",
    "    images_list = [] \n",
    "    for idx in range(len(class_path_list)):\n",
    "        if class_path_list[idx].endswith(\".jpg\"):\n",
    "            curr_img = cv2.imread(class_path_list[idx])\n",
    "            # convert image into numpy array\n",
    "            if type(curr_img).__module__ != \"numpy\":\n",
    "                curr_img = Numpy.asarray(curr_img)\n",
    "\n",
    "            images_list.append(curr_img)\n",
    "\n",
    "    print(\"Current class that is being processed: \" + class_name)\n",
    "    print(\"Current amount of images in class: \" + str(len(images_list)))\n",
    "    # augment\n",
    "    augment_images(images_list, class_name, 1000)\n",
    "\n",
    "    print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 10000 files [04:09, 40.15 files/s]\n"
     ]
    }
   ],
   "source": [
    "# create split data folder\n",
    "split_dir = \"../Material-Recognition-Data/split_data/\"\n",
    "if not os.path.isdir(split_dir):\n",
    "        os.makedirs(split_dir)\n",
    "\n",
    "# split data\n",
    "splitfolders.ratio(augmented_dir, output=split_dir, seed=1337, ratio=(0.8, 0.1, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "height = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mask():\n",
    "    images = []\n",
    "    labels = []\n",
    "    imgLabelList = [[]]\n",
    "    \n",
    "\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_img(img):\n",
    "    blur_img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    hsv_img = cv2.cvtColor(blur_img, cv2.COLOR_BGR2HSV)\n",
    "    lower_green = (25, 40, 50)\n",
    "    upper_green = (75, 255, 255)\n",
    "    mask = cv2.inRange(hsv_img, lower_green, upper_green)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    b_mask = mask > 0 \n",
    "\n",
    "    processed_img = Numpy.zeros_like(img, Numpy.uint8)\n",
    "    processed_img[b_mask] = img[b_mask]\n",
    "\n",
    "    plt.subplot(2, 3, 1); plt.imshow(img)  # Show the original image\n",
    "    plt.subplot(2, 3, 2); plt.imshow(blur_img)  # Blur image\n",
    "    plt.subplot(2, 3, 3); plt.imshow(hsv_img)  # HSV image\n",
    "    plt.subplot(2, 3, 4); plt.imshow(mask)  # Mask\n",
    "    plt.subplot(2, 3, 5); plt.imshow(b_mask)  # Boolean mask\n",
    "    plt.subplot(2, 3, 6); plt.imshow(processed_img)  # Image without background\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nn-assignment-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1385e3ba4c30d55eebf965fad9ac58cde28fb11fb3155a65b9a57d0c0f7a3ce5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
