{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import random \n",
    "from random import randint\n",
    "import numpy as Numpy\n",
    "from numpy import asarray\n",
    "from matplotlib import pyplot as plt\n",
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read folders\n",
    "base_dir = \"../Material-Recognition-Data/image/\"\n",
    "augmented_dir = \"../Material-Recognition-Data/augmented_images/\"\n",
    "masked_dir = \"../Material-Recognition-Data/mask/\"\n",
    "augmented_masked_dir = \"../Material-Recognition-Data/augmented_masked_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmenting Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(img, h, w):\n",
    "    img = cv2.resize(img, (w, h), cv2.INTER_CUBIC)\n",
    "    return img \n",
    "\n",
    "def zoom(img):\n",
    "    val = random.uniform(0.5, 1)\n",
    "    h, w = img.shape[:2]\n",
    "    h_taken = int(val*h)\n",
    "    w_taken = int(val*w)\n",
    "    h_start = randint(0, h-h_taken)\n",
    "    w_start = randint(0, w-w_taken)\n",
    "    augmented_img = img[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n",
    "    augmented_img = fill(augmented_img, h, w)\n",
    "    return augmented_img\n",
    "\n",
    "def vertical_shift(img):\n",
    "    ratio = random.uniform(-0.7, 0.7)\n",
    "    h, w = img.shape[:2]\n",
    "    to_shift = h*ratio\n",
    "    if ratio > 0: \n",
    "        augmented_img = img[:int(h-to_shift), :, :]\n",
    "    else:\n",
    "        augmented_img = img[int(-1*to_shift):, :, :]\n",
    "    augmented_img = fill(augmented_img, h, w)\n",
    "    return augmented_img\n",
    "\n",
    "def horizontal_shift(img):\n",
    "    ratio = random.uniform(-0.7, 0.7)\n",
    "    h, w = img.shape[:2]\n",
    "    to_shift = w*ratio\n",
    "    if ratio > 0:\n",
    "        augmented_img = img[:, :int(w-to_shift), :]\n",
    "    else:\n",
    "        augmented_img = img[:, int(-1*to_shift):, :]\n",
    "    augmented_img = fill(augmented_img, h, w)\n",
    "    return augmented_img\n",
    "\n",
    "def crop_square(img):\n",
    "    # target size is 128 for height, since we are going to crop out the extra width\n",
    "    target_size = 128\n",
    "    actual_size = img.shape[0]\n",
    "    scale_value = target_size/actual_size\n",
    "\n",
    "    # resize image\n",
    "    resized_img = cv2.resize(img, (0, 0), fx=scale_value, fy=scale_value)\n",
    "    \n",
    "    # crop image to square\n",
    "    center = resized_img.shape\n",
    "    width = resized_img.shape[1]\n",
    "    height = resized_img.shape[0]\n",
    "\n",
    "    if width > height:\n",
    "        desired_w = height \n",
    "        desired_h = height\n",
    "    else:\n",
    "        desired_w = width \n",
    "        desired_h = width\n",
    "\n",
    "    x = height/2 - desired_h/2\n",
    "    y = width/2 - desired_w/2 \n",
    "    cropped_img = resized_img[int(x):int(x+desired_h), int(y):int(y+desired_w)]\n",
    "    \n",
    "    return cropped_img\n",
    "\n",
    "\n",
    "def augment_images(images_list, mask_images_list, class_name, total_augment):\n",
    "    class_dir = augmented_dir + class_name + \"/\"\n",
    "    class_dir_masked = augmented_masked_dir + class_name + \"/\"\n",
    "    images_per_class = total_augment \n",
    "\n",
    "    if not os.path.isdir(class_dir):\n",
    "        os.makedirs(class_dir)\n",
    "\n",
    "    if not os.path.isdir(class_dir_masked):\n",
    "        os.makedirs(class_dir_masked)\n",
    "\n",
    "    original_count = len(images_list)\n",
    "    no_required_images = images_per_class - original_count\n",
    "    print(\"Augmenting \" + str(no_required_images) + \" images for this category ...\")\n",
    "\n",
    "    # augment images\n",
    "    while no_required_images > 0: \n",
    "        idx = no_required_images % original_count\n",
    "        copy_img = images_list[idx]\n",
    "        copy_mask_img = mask_images_list[idx]\n",
    "\n",
    "        ran_choice = randint(1, 5)\n",
    "\n",
    "        # apply diff transformations based on random selection\n",
    "        if ran_choice == 1:\n",
    "            # rotate counter clockwise\n",
    "            augmented_img = cv2.flip(copy_img, 0)\n",
    "            augmented_masked_img = cv2.flip(copy_mask_img, 0)\n",
    "        elif ran_choice == 2:\n",
    "            # rotate clockwise\n",
    "            augmented_img = cv2.flip(copy_img, 1)\n",
    "            augmented_masked_img = cv2.flip(copy_mask_img, 1)\n",
    "        elif ran_choice == 3:\n",
    "            # random zoom on image\n",
    "           augmented_img = zoom(copy_img)\n",
    "           augmented_masked_img = zoom(copy_mask_img)\n",
    "        elif ran_choice == 4:\n",
    "            # vertical shift image\n",
    "            augmented_img = vertical_shift(copy_img)\n",
    "            augmented_masked_img = vertical_shift(copy_mask_img)\n",
    "        elif ran_choice == 5:\n",
    "            # horizontal shift image\n",
    "            augmented_img = horizontal_shift(copy_img)\n",
    "            augmented_masked_img = horizontal_shift(copy_mask_img)\n",
    "       \n",
    "        # append to existing list\n",
    "        images_list.append(augmented_img)\n",
    "        mask_images_list.append(augmented_masked_img)\n",
    "        # minus required images\n",
    "        no_required_images -= 1\n",
    "\n",
    "    # save all images to new dir \n",
    "    for idx in range(len(images_list)):\n",
    "        curr_img = images_list[idx]\n",
    "\n",
    "        curr_img = crop_square(curr_img)\n",
    "        # convert BGR format to RGB format\n",
    "        curr_img = cv2.cvtColor(curr_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # convert array back to img and save\n",
    "        curr_img = Image.fromarray(curr_img)\n",
    "        # pad index with 0s \n",
    "        img_idx = f'{idx+1:04}'\n",
    "        img_name = class_name + \"_\" + img_idx + \".png\"\n",
    "        curr_img.save(class_dir + img_name)\n",
    "\n",
    "    for idx in range(len(mask_images_list)):\n",
    "        curr_img = mask_images_list[idx]\n",
    "        curr_img = crop_square(curr_img)\n",
    "        # convert BGR format to RGB format\n",
    "        curr_img = cv2.cvtColor(curr_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # convert array back to img and save\n",
    "        curr_img = Image.fromarray(curr_img)\n",
    "        # pad index with 0s \n",
    "        img_idx = f'{idx+1:04}'\n",
    "        img_name = class_name + \"_\" + img_idx + \".png\"\n",
    "        curr_img.save(class_dir_masked + img_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read images and augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current class that is being processed: fabric\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: foliage\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: glass\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: leather\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: metal\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: paper\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: plastic\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: stone\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: water\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n",
      "Current class that is being processed: wood\n",
      "Current amount of images in class: 100\n",
      "Augmenting 900 images for this category ...\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "image_folders = glob.glob(base_dir + \"*\")\n",
    "image_folders = sorted(image_folders)\n",
    "\n",
    "masked_folders = glob.glob(masked_dir + \"*\")\n",
    "masked_folders = sorted(masked_folders)\n",
    "\n",
    "for folder in range(len(image_folders)):\n",
    "    # get class name\n",
    "    class_name = os.path.basename(image_folders[folder])\n",
    "    # get all paths of images in class\n",
    "    class_path_list = glob.glob(base_dir + class_name + \"/*\")\n",
    "    masked_class_path_list = glob.glob(masked_dir + class_name + \"/*\")\n",
    "\n",
    "    # get list of images in class \n",
    "    images_list = [] \n",
    "    mask_images_list = []\n",
    "    for idx in range(len(class_path_list)):\n",
    "        if class_path_list[idx].endswith(\".jpg\"):\n",
    "            curr_img = cv2.imread(class_path_list[idx])\n",
    "            mask_img = cv2.imread(masked_class_path_list[idx])\n",
    "\n",
    "            # convert image into numpy array\n",
    "            if type(curr_img).__module__ != \"numpy\":\n",
    "                curr_img = Numpy.asarray(curr_img)\n",
    "\n",
    "            if type(mask_img).__module__ != \"numpy\":\n",
    "                mask_img = Numpy.asarray(mask_img)\n",
    "\n",
    "            \n",
    "            \n",
    "            images_list.append(curr_img)\n",
    "            mask_images_list.append(mask_img)\n",
    "\n",
    "    print(\"Current class that is being processed: \" + class_name)\n",
    "    print(\"Current amount of images in class: \" + str(len(images_list)))\n",
    "    # augment\n",
    "    augment_images(images_list, mask_images_list, class_name, 1000)\n",
    "\n",
    "    print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save only 100 of each category for test set (original has 2.5k each category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../Material-Recognition-Data/test_set/\"\n",
    "test_folders = glob.glob(test_dir + \"*\")\n",
    "test_folders = sorted(test_folders)\n",
    "\n",
    "final_test_dir = \"../Material-Recognition-Data/final_test_set/\"\n",
    "\n",
    "for folder in range(len(test_folders)):\n",
    "    class_name = os.path.basename(test_folders[folder])\n",
    "    class_path_list = glob.glob(test_dir + class_name + \"/*\")\n",
    "\n",
    "    class_dir = final_test_dir + class_name + \"/\"\n",
    "    if not os.path.isdir(class_dir):\n",
    "        os.makedirs(class_dir)\n",
    "\n",
    "    # generate 100 random indexes\n",
    "    idx_list = random.sample(range(len(class_path_list)), 100)\n",
    "\n",
    "    for idx in idx_list:\n",
    "        # read image\n",
    "        curr_img = cv2.imread(class_path_list[idx])\n",
    "        # convert image into numpy array\n",
    "        if type(curr_img).__module__ != \"numpy\":\n",
    "            curr_img = Numpy.asarray(curr_img)\n",
    "\n",
    "        # target size is 128 for height, since we are going to crop out the extra width\n",
    "        target_size = 128\n",
    "        actual_size = curr_img.shape[0]\n",
    "        scale_value = target_size/actual_size\n",
    "\n",
    "        # resize image\n",
    "        resized_img = cv2.resize(curr_img, (0, 0), fx=scale_value, fy=scale_value)\n",
    "\n",
    "        # convert BGR format to RGB format\n",
    "        curr_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # convert array back to img and save\n",
    "        curr_img = Image.fromarray(curr_img)\n",
    "        # pad index with 0s \n",
    "        img_idx = f'{idx+1:06}'\n",
    "        img_name = class_name + \"_\" + img_idx + \".png\"\n",
    "        curr_img.save(class_dir + img_name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nn-assignment-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1385e3ba4c30d55eebf965fad9ac58cde28fb11fb3155a65b9a57d0c0f7a3ce5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
